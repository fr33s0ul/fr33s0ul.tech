<!DOCTYPE html>
<html lang="en" class="dark-mode">
<head>

    <title>That path to Ai: #6 Dimensionality reduction / and ens learning to improve classifi...</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <style>
        :root {
            --button-bg-color: #ffffff;
            --button-text-color: var(--color-darkgrey);
        }
    </style>

    <link rel="stylesheet" type="text/css" href="../assets/built/screen.css?v=7717a9b749" />

    <link rel="icon" href="../favicon.png" type="image/png" />
    <link rel="canonical" href="index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="amp/index.html" />
    
    <meta property="og:site_name" content="fr33s0ul" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="That path to Ai: #6 Dimensionality reduction / and ens learning to improve classifi..." />
    <meta property="og:description" content="Dimensionality reduction is a set of machine learning-based indicative models. They are useful to execute data manipulation; it decreases the dimensionality of a dataset. It is instrumental in cases where the issue becomes intractable, and the quantity of variables increases, then dimensionality reduction leads to choosing significant variables. Low variance" />
    <meta property="og:url" content="https://fr33s0ul.tech/that-path-to-ai-6/" />
    <meta property="og:image" content="https://fr33s0ul.tech/content/images/2020/11/Dimensionality.png" />
    <meta property="article:published_time" content="2020-11-21T14:21:38.000Z" />
    <meta property="article:modified_time" content="2022-03-24T15:33:28.000Z" />
    <meta property="article:tag" content="Ai" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="That path to Ai: #6 Dimensionality reduction / and ens learning to improve classifi..." />
    <meta name="twitter:description" content="Dimensionality reduction is a set of machine learning-based indicative models. They are useful to execute data manipulation; it decreases the dimensionality of a dataset. It is instrumental in cases where the issue becomes intractable, and the quantity of variables increases, then dimensionality reduction leads to choosing significant variables. Low variance" />
    <meta name="twitter:url" content="https://fr33s0ul.tech/that-path-to-ai-6/" />
    <meta name="twitter:image" content="https://fr33s0ul.tech/content/images/2020/11/Dimensionality.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="fr33s0ul" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Ai" />
    <meta name="twitter:site" content="@fr33s0ul_Ninja" />
    <meta name="twitter:creator" content="@fr33s0ul_Ninja" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="1206" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "fr33s0ul",
        "url": "https://fr33s0ul.tech/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://fr33s0ul.tech/content/images/2020/03/logo.gif",
            "width": 300,
            "height": 41
        }
    },
    "author": {
        "@type": "Person",
        "name": "fr33s0ul",
        "image": {
            "@type": "ImageObject",
            "url": "https://fr33s0ul.tech/content/images/2020/03/asdasd.gif",
            "width": 600,
            "height": 594
        },
        "url": "https://fr33s0ul.tech/author/fr33s0ul/",
        "sameAs": [
            "https://twitter.com/fr33s0ul_Ninja"
        ]
    },
    "headline": "That path to Ai: #6 Dimensionality reduction / and ens learning to improve classifi...",
    "url": "https://fr33s0ul.tech/that-path-to-ai-6/",
    "datePublished": "2020-11-21T14:21:38.000Z",
    "dateModified": "2022-03-24T15:33:28.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://fr33s0ul.tech/content/images/2020/11/Dimensionality.png",
        "width": 1200,
        "height": 1206
    },
    "keywords": "Ai",
    "description": "Dimensionality reduction is a set of machine learning-based indicative models.\nThey are useful to execute data manipulation; it decreases the dimensionality of\na dataset. It is instrumental in cases where the issue becomes intractable, and\nthe quantity of variables increases, then dimensionality reduction leads to\nchoosing significant variables.\n\n * Low variance filter: Low Variance Filter is a valuable dimensionality\n   reduction algorithm. To comprehend it conceptually, we can take an example ",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://fr33s0ul.tech/"
    }
}
    </script>

    <meta name="generator" content="Ghost 4.41" />
    <link rel="alternate" type="application/rss+xml" title="fr33s0ul" href="../rss/index.html" />
    
    <script defer src="../public/cards.min.js?v=7717a9b749"></script>
    <link rel="stylesheet" type="text/css" href="../public/cards.min.css?v=7717a9b749">
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-111725042-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-111725042-2');
</script>
<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="http://s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5fc3b35649b48a82"></script>

<style>:root {--ghost-accent-color: #15171A;}</style>

</head>
<body class="post-template tag-ai">
<div class="viewport">

    <header id="gh-head" class="gh-head has-cover">
        <nav class="gh-head-inner inner gh-container">

            <div class="gh-head-brand">
                <a class="gh-head-logo" href="../index.html">
                        <img src="../content/images/size/w600/2020/03/logo.gif" alt="fr33s0ul" />
                </a>
                <a class="gh-burger" role="button">
                    <div class="gh-burger-box">
                        <div class="gh-burger-inner"></div>
                    </div>
                </a>
            </div>
            <div class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="../index.html">Home</a></li>
    <li class="nav-whoami"><a href="../whoami/index.html">whoami</a></li>
    <li class="nav-whispers"><a href="../whispers/index.html">Whispers</a></li>
    <li class="nav-ai"><a href="../tag/ai/index.html">Ai</a></li>
    <li class="nav-ctf"><a href="../tag/ctf/index.html">CTF</a></li>
</ul>

            </div>
            <div class="gh-head-actions">
                <div class="gh-social">
                        <a class="gh-social-twitter" href="https://twitter.com/fr33s0ul_Ninja" title="Twitter" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
                </div>

                    <a class="gh-head-button" href="index.html#/portal/signup" data-portal="signup">Subscribe</a>
            </div>
        </nav>
    </header>

    <div class="site-content">
        



<main id="site-main" class="site-main">
    <article class="article post tag-ai image-small">

        <header class="article-header gh-canvas">

            <section class="article-tag">
                <a href="../tag/ai/index.html">Ai</a>
            </section>

            <h1 class="article-title">That path to Ai: #6 Dimensionality reduction / and ens learning to improve classifi...</h1>


            <div class="article-byline">
                <section class="article-byline-content">
                    <ul class="author-list">
                        <li class="author-list-item">
                            <a href="../author/fr33s0ul/index.html" class="author-avatar">
                                <img class="author-profile-image" src="../content/images/size/w100/2020/03/asdasd.gif" alt="fr33s0ul" />
                            </a>
                        </li>
                    </ul>
                    <div class="article-byline-meta">
                        <h4 class="author-name"><a href="../author/fr33s0ul/index.html">fr33s0ul</a></h4>
                        <div class="byline-meta-content">
                            <time class="byline-meta-date" datetime="2020-11-21">Nov 21, 2020</time>
                            <span class="byline-reading-time"><span class="bull">&bull;</span> 4 min read</span>
                        </div>
                    </div>
                </section>
            </div>

            <figure class="article-image">
                <img
                    srcset="../content/images/size/w300/2020/11/Dimensionality.png 300w,
                           ../content/images/size/w600/2020/11/Dimensionality.png 600w,
                          ../content/images/size/w1000/2020/11/Dimensionality. png 1000w,
                         ../content/images/size/w2000/2020/11/Dimensionality. png 2000w"
                    sizes="(min-width: 1400px) 1400px, 92vw"
                    src="../content/images/size/w2000/2020/11/Dimensionality.png"
                    alt="That path to Ai: #6 Dimensionality reduction / and ens learning to improve classifi..."
                />
            </figure>
        </header>

        <section class="gh-content gh-canvas">
            <p>Dimensionality reduction is a set of machine learning-based indicative models. They are useful to execute data manipulation; it decreases the dimensionality of a dataset. It is instrumental in cases where the issue becomes intractable, and the quantity of variables increases, then dimensionality reduction leads to choosing significant variables.</p><ul><li><strong>Low variance filter:</strong> Low Variance Filter is a valuable dimensionality reduction algorithm. To comprehend it conceptually, we can take an example of what could look like this concept. In simple words, if you are excessively predictable, no one needs to ask your decision, Similar holds for input parameters. Low Variance Filter figures the segments variance and filters out the sections with a conflict lower than a set edge, all outstanding pieces are de-normalised to come back to their unique numerical range.</li></ul><p><br></p><ul><li><strong>High correlation filter:</strong> This dimensionality reduction algorithm attempts to dispose of inputs that are fundamentally the same as others. In other words, if your opinion is the same as your friend, one of the views is extra, and one can work. If the estimation of two input parameters is consistently the equivalent, it implies they speak to a similar entity. At that point, no need to bother with two parameters there; the algorithm will keep only one parameter.</li></ul><p><br></p><ul><li><strong>Backward feature elimination:</strong> Backward elimination is an element of choice while building a machine learning model. It is powerful to eliminate those highlights that do not significantly affect the needy variable or expectation of yield, by merely computing the sum of the square of error (SSE) after dispensing with every factor n times.</li></ul><p><br></p><ul><li><strong>Linear discriminant analysis <em>(LDA)</em>:</strong> Linear discriminant analysis is too mainstream, it is a supervised feature, extracts the method, and it does stretch out to various variants. old style LDA has the accompanying issues:</li><li>1) The acquired discriminant projection does not have great interpretability for features;</li><li>2) LDA is sensitive to noise;</li><li>3) LDA is vulnerable to the choice of the number of projection bearings.</li></ul><p>However, it does reduce the number of dimensions, n, from the first to the number of classes — 1 number of features.</p><ul><li><strong>Principal component analysis <em>(PCA)</em>:</strong> Principal component analysis (PCA) disentangles the intricacy in high-dimensional data while holding patterns and examples. It does this by changing the data into fewer dimensions, which go about as rundowns of features. PCA is an unsupervised learning technique and is like clustering; it discovers designs without reference to earlier information about whether the examples originate from various treatment gatherings or have phenotypic contrasts. PCA decreases data by geometrically projecting them onto lower dimensions called principal components (PCs), intending to find the best synopsis of the data utilising a set number of PCs.</li></ul><p><br><strong>Improving classification with ensemble learning</strong></p><p>Ensemble models in machine learning join the choices from various models to improve general performance. They work on a similar thought as wearing headphones, one will do the job, but two will be better, and mostly if it is well equalised, that is actually what ensemble learning is. By and large, when assembling a machine learning model, getting low precision and low outcomes are typical, ensemble learning procedures can be beneficial to get excellent results. It is possible by consolidating many machine learning strategies into one prescient model.</p><p>We can sort ensemble learning strategies into two classes:</p><ul><li><strong>Parallel ensemble methods:</strong> In parallel ensemble methods, base learners run in a parallel organisation. Parallel processes use the parallel age of base learners to support freedom between the base learners. The autonomy of base learners fundamentally lessens the mistake because of the use of midpoints.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../content/images/2020/11/image-23.png" class="kg-image" alt loading="lazy" width="444" height="360"><figcaption>12. <em>illustration of parallel ensemble learning technique</em></figcaption></figure><ul><li><strong>Sequential ensemble methods:</strong> Sequential ensemble procedures produce base learners in a sequence, for instance, Adaptive Boosting (AdaBoost). The sequential age of base learners advances the reliance between the base learners. The performance of the model improves by doling out higher weights to recently distorted learners.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../content/images/2020/11/image-24.png" class="kg-image" alt loading="lazy" width="660" height="144" srcset="../content/images/size/w600/2020/11/image-24.png 600w, ../content/images/2020/11/image-24.png 660w"><figcaption>13. <em>illustration of Sequential ensemble learning technique</em></figcaption></figure><p><br><strong>Most used ensemble learning techniques</strong>:</p><ul><li><strong>Bootstrap aggregating (bagging):</strong> Bagging is another way to say "Bootstrap and aggregating". Bootstrapping is a sampling method, out of the n samples accessible, k samples are picked with substitution., utilising the substitution method. The learning algorithm is then a sudden spike in demand for the models chose. The bootstrapping process uses sampling with substitutions to make the determination procedure arbitrary. At the point when a sample is a select from without substitution, the subsequent choices of variables are consistently reliant on the past determinations, thus making the standards non-irregular.<br>Model predictions go through aggregation to join them for the last forecast to think about all the outcomes conceivable. The aggregation should be possible dependent on the complete number of results, or the likelihood of predictions got from the bootstrapping of each model in the procedure.</li><li><strong>Boosting:</strong> It is a sequential ensemble learning method. Gradient boosting is one of the most utilised boosting methods. Boosting advantages is to make an assortment of predictors. In this procedure, learners are learned sequentially with early learners fitting straightforward models to the data and afterwards examining data for mistakes.</li><li><strong>Stacking:</strong> Stacking fundamentally vary from bagging and boosting on two focuses. First stacking regularly thinks about heterogeneous powerless learners (various algorithms operate synchronically) while bagging and boosting consider mostly homogeneous frail learners. At that point, we have stacking; it learns to join the base models utilising a meta-model while bagging and boosting consolidate feeble learners following deterministic algorithms.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../content/images/2022/03/crypto-coins-3.png" class="kg-image" alt loading="lazy" width="250" height="79"><figcaption>Crypto donations are appreciated for more free content and exciting topics <strong>0x684c21519d43E415506c1750c08FA0A97621FFEF</strong></figcaption></figure>
        </section>


    </article>
</main>


    <section class="footer-cta cta-alt">
        <div class="inner">
            <h2>Sign up for more like this.</h2>
            <a class="footer-cta-button" href="index.html#/portal" data-portal>
                <div class="footer-cta-input">Enter your email</div>
                <span>Subscribe</span>
            </a>
        </div>
    </section>




            <aside class="read-more-wrap">
                <div class="read-more inner">
                        
<article class="post-card post ">

    <a class="post-card-image-link" href="../that-path-to-ai-8-hacking-ai-with-adv-machine-learning/index.html">
        <img class="post-card-image"
            srcset="../content/images/size/w300/2020/11/aiHackss-1.gif 300w,
                   ../content/images/size/w600/2020/11/aiHackss-1. gif 600w,
                  ../content/images/size/w1000/2020/11/aiHackss-1. gif 1000w,
                 ../content/images/size/w2000/2020/11/aiHackss-1. gif 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="../content/images/size/w600/2020/11/aiHackss-1.gif"
            alt="That path to Ai: #8 Hacking Ai with Adv machine learning"
            loading="lazy"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../that-path-to-ai-8-hacking-ai-with-adv-machine-learning/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">That path to Ai: #8 Hacking Ai with Adv machine learning</h2>
            </header>
            <div class="post-card-excerpt">
                <p>Adversarial machine learning Adversarial machine learning exploits how artificial intelligence algorithms work to disrupt the conduct of artificial intelligence algorithms. In the past years, adversarial machine learning has become an active zone of research as the job of AI continues to grow in vast numbers of the applications we use.</p>
            </div>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../author/fr33s0ul/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2020/03/asdasd.gif" alt="fr33s0ul" loading="lazy" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span class="post-card-byline-author"><a href="../author/fr33s0ul/index.html">fr33s0ul</a></span>
                <span class="post-card-byline-date"><time datetime="2020-11-21">Nov 21, 2020</time> <span class="bull">&bull;</span> 3 min read</span>
            </div>
        </footer>

    </div>

</article>
                        
<article class="post-card post ">

    <a class="post-card-image-link" href="../that-path-to-ai-7/index.html">
        <img class="post-card-image"
            srcset="../content/images/size/w300/2020/11/dnn.png 300w,
                   ../content/images/size/w600/2020/11/dnn.png 600w,
                  ../content/images/size/w1000/2020/11/dnn. png 1000w,
                 ../content/images/size/w2000/2020/11/dnn. png 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="../content/images/size/w600/2020/11/dnn.png"
            alt="That path to Ai: #7 CNNs, RNNs, Feature eng ML / imputaxon"
            loading="lazy"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../that-path-to-ai-7/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">That path to Ai: #7 CNNs, RNNs, Feature eng ML / imputaxon</h2>
            </header>
            <div class="post-card-excerpt">
                <p>Convolutional Neural Networks (CNNs) A Convolutional Neural Networks (CNNs) is a Deep Learning algorithm which can take in an input picture, appoint significance (learnable weights and biases) to different articles in the image and have the option to separate one from the other. The pre-processing required in a CNNs; it</p>
            </div>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../author/fr33s0ul/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2020/03/asdasd.gif" alt="fr33s0ul" loading="lazy" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span class="post-card-byline-author"><a href="../author/fr33s0ul/index.html">fr33s0ul</a></span>
                <span class="post-card-byline-date"><time datetime="2020-11-21">Nov 21, 2020</time> <span class="bull">&bull;</span> 3 min read</span>
            </div>
        </footer>

    </div>

</article>
                        
<article class="post-card post ">

    <a class="post-card-image-link" href="../that-path-to-ai-5/index.html">
        <img class="post-card-image"
            srcset="../content/images/size/w300/2020/11/godsperf.jpg 300w,
                   ../content/images/size/w600/2020/11/godsperf.jpg 600w,
                  ../content/images/size/w1000/2020/11/godsperf.jpg 1000w,
                 ../content/images/size/w2000/2020/11/godsperf.jpg 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="../content/images/size/w600/2020/11/godsperf.jpg"
            alt="That path to Ai: #5 Performance evaluation"
            loading="lazy"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../that-path-to-ai-5/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">That path to Ai: #5 Performance evaluation</h2>
            </header>
            <div class="post-card-excerpt">
                <p>Now that we covered a fair amount of the components and instruments involving in the AI systems, it is the time to talk a little about performance evaluation and its importance. Performance evaluation is an essential step in a methodological operation. Because after finishing the whole machine learning model, testing</p>
            </div>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../author/fr33s0ul/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2020/03/asdasd.gif" alt="fr33s0ul" loading="lazy" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span class="post-card-byline-author"><a href="../author/fr33s0ul/index.html">fr33s0ul</a></span>
                <span class="post-card-byline-date"><time datetime="2020-11-21">Nov 21, 2020</time> <span class="bull">&bull;</span> 3 min read</span>
            </div>
        </footer>

    </div>

</article>
                </div>
            </aside>



    </div>

    <footer class="site-footer outer">
        <div class="inner">
            <section class="copyright"><a href="../index.html">fr33s0ul</a> &copy; 2022</section>
            <nav class="site-footer-nav">
                
            </nav>
            <div><a href="https://ghost.org/" target="_blank" rel="noopener">Powered by Ghost</a></div>
        </div>
    </footer>

</div>


<script
    src="https://code.jquery.com/jquery-3.5.1.min.js"
    integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous">
</script>
<script src="../assets/built/casper.js?v=7717a9b749"></script>
<script>
$(document).ready(function () {
    // Mobile Menu Trigger
    $('.gh-burger').click(function () {
        $('body').toggleClass('gh-head-open');
    });
    // FitVids - Makes video embeds responsive
    $(".gh-content").fitVids();
});
</script>



</body>
</html>
